{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:171: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[-4.08561915e-05  1.22735365e-03]]\n",
      "Intercept: \n",
      " [-0.0103569]\n",
      "Mean Absolute Error: 0.015280974889755711\n",
      "Mean Squared Error: 0.0004816537281441266\n",
      "Root Mean Squared Error: 0.02194661085780961\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           price change   R-squared:                       0.006\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     1.398\n",
      "Date:                Sun, 26 Apr 2020   Prob (F-statistic):              0.248\n",
      "Time:                        13:47:34   Log-Likelihood:                 1131.8\n",
      "No. Observations:                 498   AIC:                            -2258.\n",
      "Df Residuals:                     495   BIC:                            -2245.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0116      0.008     -1.509      0.132      -0.027       0.004\n",
      "ShiftedPB     -0.0002      0.004     -0.040      0.968      -0.008       0.007\n",
      "ShiftedPS      0.0014      0.002      0.645      0.519      -0.003       0.006\n",
      "==============================================================================\n",
      "Omnibus:                       73.327   Durbin-Watson:                   2.178\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              309.440\n",
      "Skew:                          -0.576   Prob(JB):                     6.40e-68\n",
      "Kurtosis:                       6.686   Cond. No.                         71.9\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import random\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# function to scan the date given and see what month number it should be assigned\n",
    "# the numbering works so that January of 2018 is 1, April of 2018 is 4,\n",
    "# January of 2019 is 13, and so forth\n",
    "def get_month_number(date):\n",
    "  month = date.split(\"/\")[0]\n",
    "  month_num = int(month)\n",
    "  year = date.split(\"/\")[2]\n",
    "  year = int(year)\n",
    "  if year == 2019:\n",
    "    month_num += 12\n",
    "  return month_num\n",
    "\n",
    "\n",
    "# function that takes each Sunday date and calculates the dates for the 5 weekdays for the coming\n",
    "# week. So if you have 1/7/2018, the output will be the following weekdays: 1/8/2018, 1/9/2018, 1/10/2018, \n",
    "# 1/11/2018, and 1/12/2018.\n",
    "# ASSUMPTION: each week starts on Sunday and the input date is in the form year-month-day WITH DASHES\n",
    "# ASSUMPTIONS CONT.: the format of the date for the prices dateframe is month/day/year WITH FORWARD SLASH\n",
    "def get_weekdays(date_str):\n",
    "  given_date = datetime.strptime(date_str, '%Y-%m-%d').date()\n",
    " # print(type(given_date))\n",
    " # print(given_date)\n",
    "  monday = given_date + timedelta(days=1)\n",
    "  tuesday = given_date + timedelta(days=2)\n",
    "  wednesday = given_date + timedelta(days=3)\n",
    "  thursday = given_date + timedelta(days=4)\n",
    "  friday = given_date + timedelta(days=5)\n",
    "\n",
    "  # reformat dates into the right format for the prices dataframe\n",
    "  monday = '{0.month}/{0.day}/{0.year}'.format(monday)\n",
    "  tuesday = '{0.month}/{0.day}/{0.year}'.format(tuesday)\n",
    "  wednesday = '{0.month}/{0.day}/{0.year}'.format(wednesday)\n",
    "  thursday = '{0.month}/{0.day}/{0.year}'.format(thursday)\n",
    "  friday = '{0.month}/{0.day}/{0.year}'.format(friday)\n",
    "\n",
    "  return[monday, tuesday, wednesday, thursday, friday]\n",
    "\n",
    "\n",
    "# arranges the weekdays in an array of arrays with the format of \n",
    "# [[date, weekly mentions], [date, weekly mentions], ..., [date, weekly mentions]]\n",
    "# index 1 should be the same for all the days of a given week.\n",
    "def build_date_mention_arr(array_of_dates, mentions):\n",
    "  m = array_of_dates[0]\n",
    "  tu = array_of_dates[1]\n",
    "  w = array_of_dates[2]\n",
    "  th = array_of_dates[3]\n",
    "  f = array_of_dates[4]\n",
    "\n",
    "  date_mention_arr = [[m, mentions], [tu, mentions], [w, mentions], [th, mentions], [f, mentions]]\n",
    "  return date_mention_arr\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "#############################################      set STOCK and MODELTYPE     ############################################\n",
    "STOCK = 'twtr'\n",
    "# enter stock ticker\n",
    "MODELTYPE = 'fundamental'   \n",
    "# MODELTYPE: 'all', 'hype', or 'fundamental'\n",
    "\n",
    "# read in the prices file with the pandas library to create a dataframe\n",
    "prices = pd.read_csv(STOCK + '-prices-18-19.csv', skiprows=1, skip_blank_lines=True)\n",
    "\n",
    "# filter out rows with empty stock values. they randomly appear throughout both 2018 and 2019\n",
    "a = 0\n",
    "for ind in prices.index: \n",
    "    n = prices['Open'][ind]\n",
    "    if (math.isnan(n))==True:\n",
    "      prices.drop([a], inplace=True)\n",
    "    a += 1\n",
    "\n",
    "# reset indices for rows after deleting rows to get continguous numbers\n",
    "prices.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# delete all columns except the date and close value\n",
    "prices.drop(['High', 'Low', 'Volume'], axis=1, inplace=True)\n",
    "\n",
    "# add a new column for the month number to the table\n",
    "# month numbers are 1-24, January 2018 is month 1 and January 2019 is month 13\n",
    "prices['Month Number'] = prices.apply(lambda row: get_month_number(row.Date), axis = 1) \n",
    "#print(prices)\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# read in the trends csv (weekly mentions)\n",
    "trends = pd.read_csv(STOCK + '-trends.csv', skiprows=1, skip_blank_lines=True)\n",
    "trends = trends.rename(columns={\"$\"+ STOCK +\": (United States)\": \"Weekly Mentions\"})\n",
    "\n",
    "#trends.head()\n",
    "\n",
    "# change type of \"Week\" column to datetime type, to easily get the dates of the next 5 days\n",
    "for ind in trends.index: \n",
    "    d = trends['Week'][ind]\n",
    "    mentions = trends['Weekly Mentions'][ind]\n",
    "    dates_arr = get_weekdays(d)\n",
    "    #print(dates_arr)\n",
    "    # dates_arr[0] == monday, dates_arr[1] == tuesday, etc.\n",
    "    d_m_arr = build_date_mention_arr(dates_arr, mentions)\n",
    "    #print(d_m_arr)\n",
    "\n",
    "    mini_trends_df = pd.DataFrame(d_m_arr, columns=['Week', 'Weekly Mentions'])\n",
    "    #print(mini_trends_df)\n",
    "    trends = trends.append(mini_trends_df, ignore_index=True)\n",
    "\n",
    "#print(trends)\n",
    "\n",
    "\n",
    "# trends now has initial Sunday dates, plus all the new, reformatted week days to match the formatting in the prices df\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# combine the two dataframes (prices and trends) based on the unique ID (date), add the weekly mentions column to the existing prices\n",
    "# df. create a new name for this combined df. \n",
    "\n",
    "trends = trends.rename(columns={\"Week\": \"Date\"})\n",
    "\n",
    "prices_and_trends = pd.merge(left=prices, right=trends, left_on='Date', right_on='Date')\n",
    "\n",
    "# prices_and_trends is a dataframe that contains the columns: Date, Close ($ value), Month Number (for randomizing training/test sets),\n",
    "# and Weekly Mentions (every day has the weekly mentions for its respective week) \n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# reading in the indicators csv to create a new df\n",
    "\n",
    "indicators = pd.read_csv(STOCK + '-indicators.csv', skiprows=1, skip_blank_lines=True)\n",
    "\n",
    "# filter out rows with empty indicator values. they randomly appear throughout the file\n",
    "c = 0\n",
    "for ind in indicators.index: \n",
    "    n = indicators['Volume'][ind]\n",
    "    if (math.isnan(n))==True:\n",
    "      indicators.drop([c], inplace=True)\n",
    "    c += 1\n",
    "\n",
    "\n",
    "prices_trends_and_indicators = pd.merge(left=prices_and_trends, right=indicators, left_on='Date', right_on='Date')\n",
    "prices_trends_and_indicators['price change'] = np.nan\n",
    "start = 0\n",
    "for i in range(1,len(prices_trends_and_indicators['price change'])):\n",
    "    open_price = prices_trends_and_indicators['Open'][i]\n",
    "    close_price = prices_trends_and_indicators['Close'][i]\n",
    "    prices_trends_and_indicators['price change'][start] = float((close_price-open_price)/open_price)\n",
    "    start+=1\n",
    "\n",
    "    \n",
    "if MODELTYPE == 'all':\n",
    "    indicators_to_shift = ['Weekly Mentions', 'Volume', 'PB', 'PS', 'MOA']\n",
    "elif MODELTYPE == 'hype':\n",
    "    indicators_to_shift = ['Weekly Mentions', 'Volume', 'MOA']\n",
    "elif MODELTYPE == 'fundamental':\n",
    "    indicators_to_shift = ['PB', 'PS']\n",
    "else:\n",
    "    print(\"Invalid MODELTYPE\")\n",
    "    \n",
    "for indi in indicators_to_shift:\n",
    "    shifted_indicator = prices_trends_and_indicators[indi][:-1]\n",
    "    shifted_indicator_title = 'Shifted' + indi\n",
    "    prices_trends_and_indicators[shifted_indicator_title]= shifted_indicator.astype(float)\n",
    "# prices_trends_and_indicators is a dataframe that contains the important columns from each of the three csv files\n",
    "# prices, trends, and indicators. The columns are: Date, Close ($ value), Month Number (for randomizing training/test sets),\n",
    "# and Weekly Mentions (every day has the weekly mentions for its respective week), Volume, PB, PS, and MOA\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "# write the prices_trends_and_indicators dataframe to a csv file, just in case for future reference\n",
    "\n",
    "prices_trends_and_indicators.to_csv(STOCK + '-prices-trends-indicators-fin.csv', index = False)\n",
    "prices_trends_and_indicators.head()\n",
    "#print(len(prices_trends_and_indicators))\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "# create the randomization of months (numbered 1-24) for the training and test set\n",
    "\n",
    "order_arr = []\n",
    "while len(order_arr) < 17:\n",
    "  n = random.randint(1,17)\n",
    "  if n not in order_arr:\n",
    "    order_arr.append(n)\n",
    "\n",
    "# split the randomly ordered array of month numbers into the training and test sets\n",
    "# the training set takes 16 months of the data and the test set takes 8 months of the data\n",
    "training_set = order_arr[0:11]\n",
    "test_set = order_arr[11:]\n",
    "#print(training_set)\n",
    "#print(test_set)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "# statistcal details of the dataset\n",
    "prices_trends_and_indicators.describe()\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "if MODELTYPE == 'all':\n",
    "    shifted_df = prices_trends_and_indicators[['price change','ShiftedWeekly Mentions', 'ShiftedVolume', 'ShiftedPB', 'ShiftedPS', 'ShiftedMOA']].copy()\n",
    "elif MODELTYPE == 'hype':\n",
    "    shifted_df = prices_trends_and_indicators[['price change','ShiftedWeekly Mentions', 'ShiftedVolume', 'ShiftedMOA']].copy()\n",
    "elif MODELTYPE == 'fundamental':\n",
    "    shifted_df = prices_trends_and_indicators[['price change', 'ShiftedPB', 'ShiftedPS']].copy()\n",
    "\n",
    "\n",
    "\n",
    "remove_na_shifted = shifted_df.dropna()\n",
    "#print(len(shifted_df.dropna()))\n",
    "#print(remove_na_shifted.head())\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "# carry out multivariate linear regression for training and predictive purposes\n",
    "\n",
    "# separate the independent variables (in X) and dependent variable (in y)\n",
    "\n",
    "if MODELTYPE == 'all':\n",
    "    X = remove_na_shifted[['ShiftedWeekly Mentions', 'ShiftedVolume', 'ShiftedPB', 'ShiftedPS', 'ShiftedMOA']]\n",
    "elif MODELTYPE == 'hype':\n",
    "    X = remove_na_shifted[['ShiftedWeekly Mentions', 'ShiftedVolume', 'ShiftedMOA']]\n",
    "elif MODELTYPE == 'fundamental':\n",
    "    X = remove_na_shifted[['ShiftedPB', 'ShiftedPS']]\n",
    "\n",
    "    \n",
    "y = remove_na_shifted['price change']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "# carry out multivariate linear regression for training and predictive purposes\n",
    "\n",
    "# separate the independent variables (in X) and dependent variable (in y)\n",
    "# X = prices_trends_and_indicators[['Weekly Mentions', 'Volume', 'PB', 'PS', 'MOA']]\n",
    "# y = prices_trends_and_indicators['Close']\n",
    "\n",
    "x1 = X[0:30]\n",
    "x2 = X[30:60]\n",
    "x3 = X[60:90]\n",
    "x4 = X[90:120]\n",
    "x5 = X[120:150]\n",
    "x6 = X[150:180]\n",
    "x7 = X[180:210]\n",
    "x8 = X[210:240]\n",
    "x9 = X[240:270]\n",
    "x10 = X[270:300]\n",
    "x11 = X[300:330]\n",
    "x12 = X[330:360]\n",
    "x13 = X[360:390]\n",
    "x14 = X[390:420]\n",
    "x15 = X[420:450]\n",
    "x16 = X[450:480]\n",
    "x17 = X[480:499]\n",
    "\n",
    "y1 = y[0:30]\n",
    "y2 = y[30:60]\n",
    "y3 = y[60:90]\n",
    "y4 = y[90:120]\n",
    "y5 = y[120:150]\n",
    "y6 = y[150:180]\n",
    "y7 = y[180:210]\n",
    "y8 = y[210:240]\n",
    "y9 = y[240:270]\n",
    "y10 = y[270:300]\n",
    "y11 = y[300:330]\n",
    "y12 = y[330:360]\n",
    "y13 = y[360:390]\n",
    "y14 = y[390:420]\n",
    "y15 = y[420:450]\n",
    "y16 = y[450:480]\n",
    "y17 = y[480:499]\n",
    "\n",
    "dx={1:x1, 2:x2, 3:x3, 4:x4, 5:x5, 6:x6, 7:x7, 8:x8, 9:x9, 10:x10, 11:x11, 12:x12, 13:x13, 14:x14, 15:x15, 16:x16, 17:x17}\n",
    "pd.concat(dx)\n",
    "\n",
    "dy={1:y1, 2:y2, 3:y3, 4:y4, 5:y5, 6:y6, 7:y7, 8:y8, 9:y9, 10:y10, 11:y11, 12:y12, 13:y13, 14:y14, 15:y15, 16:y16, 17:y17}\n",
    "pd.concat(dy)\n",
    "X_train = pd.DataFrame()\n",
    "y_train = pd.DataFrame()\n",
    "X_test = pd.DataFrame()\n",
    "y_test = pd.DataFrame()\n",
    "for i in training_set:\n",
    "    x_train_temp = dx[i]\n",
    "    y_train_temp = dy[i]\n",
    "    X_train = pd.concat([X_train, x_train_temp], ignore_index=False)\n",
    "    y_train = pd.concat([y_train, y_train_temp], ignore_index=False)\n",
    "    \n",
    "    \n",
    "for j in test_set:\n",
    "    x_test_temp = dx[j]\n",
    "    y_test_temp = dy[j]\n",
    "    X_test = pd.concat([X_test, x_test_temp], ignore_index=False)\n",
    "    y_test = pd.concat([y_test, y_test_temp], ignore_index=False)\n",
    "\n",
    "\n",
    "# regressor = LinearRegression()  \n",
    "# regressor.fit(X_train, y_train)\n",
    "\n",
    "# # to check the coefficients and intercept used for the independent variables\n",
    "# print(\"Coefficients: \\n\", regressor.coef_)\n",
    "# print(\"Intercept: \\n\", regressor.intercept_)\n",
    "# print(len(X_train))\n",
    "# X_train.fillna(X_train.mean(), inplace=True)\n",
    "# print(X_train)\n",
    "\n",
    "# for item in X_train['ShiftedVolume']:\n",
    "#     if item==np.nan:\n",
    "#         print(0)\n",
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# to check the coefficients and intercept used for the independent variables\n",
    "print(\"Coefficients: \\n\", regressor.coef_)\n",
    "print(\"Intercept: \\n\", regressor.intercept_)\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "y_new_test = y_test.to_numpy()\n",
    "\n",
    "# check actual vs. predicted values\n",
    "\n",
    "# act_vs_pred = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "# act_vs_pred.head()\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print('Mean Absolute Error:', mae)  \n",
    "print('Mean Squared Error:', mse)  \n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "# get a summary with statsmodels\n",
    "X = sm.add_constant(X) # adding a constant\n",
    " \n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X) \n",
    " \n",
    "mod_sum = model.summary()\n",
    "print(mod_sum)\n",
    "\n",
    "# write model summary to new file\n",
    "file = open(STOCK+\"-\"+MODELTYPE+\"-modelsummary.txt\",\"w\")\n",
    " \n",
    "L = [mae, mse, rmse, mod_sum] \n",
    "L_labels = ['Mean Absolute Error', 'Mean Squared Error', 'Root Mean Squared Error', 'Model Summary']\n",
    "count = 0\n",
    "for line in L:\n",
    "    str_line = str(line)\n",
    "    file.write(L_labels[count] + \": \" + str_line + \"\\n\")\n",
    "    count += 1\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
